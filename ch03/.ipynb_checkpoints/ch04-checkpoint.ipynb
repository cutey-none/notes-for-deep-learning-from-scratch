{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df942424-8e1d-488e-a711-010cc518c44a",
   "metadata": {},
   "source": [
    "#### 4.2.4 mini-batch版交叉熵误差的实现（P91）\n",
    "\n",
    "这里的笔记内容是，针对于one-hot数据和非one-hot数据（标签形式）数据的疑惑，首先看下one-hot实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f8d11e9-86c4-49d7-9520-74d9afbc78b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error_one_hot(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(t * np.log(y + 1e-7)) / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5ef779-d726-4610-b543-3a84998a2bd3",
   "metadata": {},
   "source": [
    "再来看看非one-hot的实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f4366a7-7190-4aae-8f6c-0fe58f2e4a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9358099e-bb5f-4c27-8beb-e37d857463b4",
   "metadata": {},
   "source": [
    "可以看到，两种方式的区别在于前者是使用的`t * np.log(y + 1e-7)`，后者是使用`np.log(y[np.arange(batch_size), t] + 1e-7)`，学习到这里的时候我是很疑问的，**因为按照87页的交叉熵误差公式来说前者是更符合的。**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad738b0-f2aa-4d81-813c-9125c97b7ec1",
   "metadata": {},
   "source": [
    "先来简单回忆下交叉熵误差是用来干啥的，为了简单，我们就拿2组数据来比较，如果第一组正确的标签是2，算法识别的概率是0.6，那么交叉熵的概率应该是-log0.6约等于0.51，第二组的标签是3，算法识别的概率是0.1，那么交叉熵为-log0.1约等于2.30，此时的平均损失函数为`(0.51 + 2.30) / 2 = 1.405`。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326e67f2-1d43-4491-8685-22c08b3e2f98",
   "metadata": {},
   "source": [
    "基于上面这个简单的例子，特别说明下，为了后面的编写简单，监督数据是5维的数据，也就是只识别0-4这5个标签，我们代入上面的两种代码中，先来看下one-hot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4e5667-64a1-4467-8fd9-c3a101625fc3",
   "metadata": {},
   "source": [
    "t[0]为[0,0,1,0,0]，t[1]为[0,0,0,1,0]，所以t就是一个2行5列的矩阵，那么对应的y其实也是个2行5列的矩阵，**注意，这里可能有一小部分同学学混了，以前不是A矩阵的列等于B举证的行才能A*B，是的，但是这里的不是相乘，而是点乘，也称为哈达马积，此时要求AB两个矩阵的shape是一样的。** y[0]为[0.1, 0.1, 0.6, 0, 0.25]，y[1]为[0.05, 0.15, 0,1, 0.1, 0.6]，此时的平均损失函数大概才为1.405，直接计算下看看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0ec77516-669f-417e-af00-6eb77ca85ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 5)\n",
      "(2, 5)\n",
      "1.406704775046942\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "y = np.array([[0.1, 0.1, 0.6, 0, 0.25],[0.05, 0.15, 0.1, 0.1, 0.6]])\n",
    "print(y.shape)\n",
    "t = np.array([[0,0,1,0,0],[0,0,0,1,0]])\n",
    "print(t.shape)\n",
    "print(cross_entropy_error_one_hot(y, t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7631e8-37b3-4e80-89ff-d821ac730219",
   "metadata": {},
   "source": [
    "可以看到这里t的作用只是把y里面其他概率的干扰项给屏蔽掉，聚焦于标签的概率，即识别为2和3的平均概率。那继续看，如果是标签形式的数据，t的shape就是(1, 5)，即t = [2, 3]，表示t的第0个标签是2，第1个标签是3。那么对于y来说，识别为2的概率的位置在哪，是不是就是y矩阵里的第0行第2列，识别为3的位置就是第1行第3列。也就是说`y[np.arange(batch_size),t]`能抽出各个数据的正确解标签对应的神经网络的输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "37741df0-956c-415d-af34-1f73f43c941b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,)\n",
      "[0.6 0.1]\n"
     ]
    }
   ],
   "source": [
    "t = np.array([2, 3])\n",
    "print(t.shape)\n",
    "batch_size = y.shape[0]\n",
    "print(y[np.arange(batch_size), t])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34abb88f-b1f8-4643-9baa-853a5ca3d46c",
   "metadata": {},
   "source": [
    "可以看到此时就是针对0.6和0.1做log计算求和再平均，和one-hot就是一样的结果了。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
